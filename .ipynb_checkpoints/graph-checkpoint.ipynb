{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"Data\"\n",
    "csv_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name:str)->pd.DataFrame:\n",
    "    cols = [\"id\",\"author\",\"title\"]\n",
    "    if name == \"out-dblp_proceedings.csv\":\n",
    "        cols = [\"id\",\"editor\",\"title\"]\n",
    "        \n",
    "    df = pd.read_csv(\n",
    "    \"Data/\" + name,\n",
    "    delimiter=\";\",\n",
    "    usecols=cols,\n",
    "    nrows=500\n",
    "    )\n",
    "    df.name = name.split(\".\")[0]\n",
    "    df.rename(columns={\"editor\":\"author\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_list = list()\n",
    "for csv in csv_list:\n",
    "    df_list.append(\n",
    "        read_csv(csv)\n",
    "    )\n",
    "    df_list[-1].dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df:pd.DataFrame)->nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    for publication_id, row in df.iterrows():\n",
    "        authors = row[\"author\"].split(\"|\")\n",
    "        title = row[\"title\"]\n",
    "        G.add_node(publication_id, bipartite = 0, title=title, authors_counter = len(authors))\n",
    "        for author in authors:\n",
    "            G.add_node(author, bipartite = 1)\n",
    "            G.add_edge(publication_id,author)\n",
    "    return G\n",
    "\n",
    "graph_list = list()\n",
    "for df in df_list:\n",
    "    graph_list.append(\n",
    "        create_graph(df)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "Bringing Semantics to Web Services with OWL-S. \n",
      " ['David L. Martin 0001', 'Deborah L. McGuinness', 'Drew V. McDermott', 'Evren Sirin', 'Katia P. Sycara', 'Mark H. Burstein', 'Massimo Paolucci 0001', 'Naveen Srinivasan', 'Sheila A. McIlraith'] \n",
      " wich has 9 authors\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "A Framework of Information System Concepts (The FRISCO Report). \n",
      " ['Alexander A. Verrijn-Stuart', 'Björn E. Nilsson', 'Colette Rolland', 'Eckhard D. Falkenberg', 'Frans Van Assche', 'J. L. Han Oei', 'Klaus Voss', 'Paul Lindgreen', 'Ronald K. Stamper', 'Wolfgang Hesse'] \n",
      " wich has 10 authors\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "CoolEmAll: Models and Tools for Planning and Operating Energy Efficient Data Centres. \n",
      " ['Andrew Donoghue', 'Ariel Oleksiak', 'Daniel Rathgeb', 'Enric Pages', 'Eugen Volk', 'Georges Da Costa', 'Georgina Gallizo', 'Jaume Salom', 'Jean-Marc Pierson', 'Jochen Buchholz', 'Lara Lopez', 'Laura Sisó', 'Leandro F. Cupertino', 'Mateusz Jarus', 'Micha vor dem Berge', 'Thomas Zilio', 'Tomasz Piontek', 'Uwe Wössner', 'Wojciech Piatek'] \n",
      " wich has 19 authors\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "R-GMA: An Information Integration System for Grid Monitoring. \n",
      " ['Abdeslem Djaoui', 'Alasdair J. G. Gray', 'Andrew W. Cooke', 'Antony J. Wilson', 'Brian A. Coghlan', \"David O'Callaghan\", 'James Magowan', 'Jason Leake', 'Laurence Field', 'Linda Cornwall', 'Lisha Ma', 'Manfred Oevers', 'Manish Soni', 'Norbert Podhorszki', 'Paul Taylor', 'Rob Byrom', 'Roney Cordenonsi', 'Steve Fisher', 'Steve Hicks', 'Stuart Kenny', 'Werner Nutt'] \n",
      " wich has 21 authors\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "Shadow Paging Is Feasible. \n",
      " ['Tatu Ylönen'] \n",
      " wich has 1 authors\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "Programming Data Structures in Logic. \n",
      " ['Russell Turpin'] \n",
      " wich has 1 authors\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "Proceedings of the Fifth Workshop on Technologies for Machine Translation of Low-Resource Languages, LoResMT@COLING 2022, Gyeongju, Republic of Korea, October 12 - 17, 2022. \n",
      " ['Atul Kr. Ojha', 'Chao-Hong Liu', 'Ekaterina Vylomova', 'Jade Abbott', 'Jonathan Washington', 'Nathaniel Oco', 'Tommi A. Pirinen', 'Valentin Malykh', 'Varvara Logacheva', 'Xiaobing Zhao'] \n",
      " wich has 10 authors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pubblicazione con maggior numero di autori:\n",
    "\n",
    "def get_publication_with_max_authors(G:nx.Graph)->tuple[str, list[str], int]:\n",
    "    publication_ids = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    publication_ids = list(publication_ids)\n",
    "\n",
    "    authors_counter_array = np.array(\n",
    "        list(map(lambda id: G.nodes[id][\"authors_counter\"], publication_ids))\n",
    "        )\n",
    "\n",
    "    max_authors_pubication_id = publication_ids[authors_counter_array.argmax()]\n",
    "\n",
    "    authors = G.neighbors(max_authors_pubication_id)\n",
    "    title = G.nodes[max_authors_pubication_id][\"title\"]\n",
    "\n",
    "    return (\n",
    "        title,\n",
    "        list(authors),\n",
    "        G.nodes[max_authors_pubication_id]['authors_counter']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    title, authors, counter = get_publication_with_max_authors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"{title} \\n {list(authors)} \\n wich has {counter} authors\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "The author with most collaborators is Jean-Michel Knippel, with 8 collaborators:\n",
      "['Jules Nyssen', 'Jean-Luc Massat', 'Christophe Bisière', 'Edmond Bianco', 'Mohamed Tayeb Laskri', 'Clyde Chabot', 'Denis Iwanesko', 'Renaud Litré']\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "The author with most collaborators is Alexander A. Verrijn-Stuart, with 9 collaborators:\n",
      "['Ronald K. Stamper', 'Colette Rolland', 'Wolfgang Hesse', 'Eckhard D. Falkenberg', 'Klaus Voss', 'J. L. Han Oei', 'Paul Lindgreen', 'Frans Van Assche', 'Björn E. Nilsson']\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "The author with most collaborators is Tuncer I. Ören, with 37 collaborators:\n",
      "['Umang Kant', 'Umut Durak', 'Laurent Capocchi', 'Yang Liu', 'Paul A. Fishwick', 'Lin Zhang 0009', 'Maâmar El-Amine Hamri', 'Alison Harper', 'Rhys Goldstein', 'Nico Formanek', 'Azam Khan', 'Valdemar Vicente Graciano Neto', 'Cláudio Gomes 0001', 'Thorsten Pawletta', 'Raymond R. Hill', 'Balqies Sadoun', 'Mohammad S. Obaidat', 'Lance E. Champagne', 'Margaret L. Loper', 'Paul K. Davis', 'Bo Hu Li 0001', 'Claudia Szabo', 'Saurabh Mittal', 'Saikou Y. Diallo', 'Baocun Hou', 'Navonil Mustafee', 'Jean François Santucci', 'Mamadou Kaba Traoré', 'Mayank Singh 0008', 'Ernest H. Page', 'Andreas Tolk', 'Bernard P. Zeigler', 'Juan Manuel Durán', 'Gregory Zacharewicz', 'Tingyu Lin', 'Breno Bernard Nicolau de França', 'Yuanjun Laili']\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "The author with most collaborators is Werner Nutt, with 25 collaborators:\n",
      "['Manfred Oevers', 'Norbert Podhorszki', 'Lisha Ma', 'Manish Soni', 'Yaron Kanza', 'Jason Leake', 'Laurence Field', 'Sara Cohen', 'Steve Hicks', 'Alexander Serebrenik', 'Stuart Kenny', 'Steve Fisher', 'Rob Byrom', 'Alasdair J. G. Gray', 'Antony J. Wilson', \"David O'Callaghan\", 'Paul Taylor', 'Linda Cornwall', 'Brian A. Coghlan', 'Andrew W. Cooke', 'Abdeslem Djaoui', 'Roney Cordenonsi', 'Yehoshua Sagiv', 'Yakov A. Kogan', 'James Magowan']\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "The author with most collaborators is None, with 0 collaborators:\n",
      "[]\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "The author with most collaborators is None, with 0 collaborators:\n",
      "[]\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "The author with most collaborators is Klaus Jansen, with 35 collaborators:\n",
      "['Dorit S. Hochbaum', 'Samir Khuller', 'José D. P. Rolim', 'Uri Zwick', 'Naveen Garg 0001', 'Josep Díaz', 'Sofya Raskhodnikova', 'Leslie Ann Goldberg', 'Anup Rao 0001', 'Ashish Goel', 'Ronitt Rubinfeld', 'Santosh S. Vempala', 'David Steurer', 'Rocco A. Servedio', 'Nikhil R. Devanur', 'Eric Blais', 'Maria J. Serna', 'Prasad Raghavendra', 'Ronen Shaltiel', 'Claire Mathieu', 'Irit Dinur', 'Vijay V. Vazirani', 'Cristopher Moore', 'R. Ravi 0001', 'Chandra Chekuri', 'Stefano Leonardi 0001', 'Dana Ron', 'Chris Umans', 'David Williamson', 'Joseph Naor', 'Anupam Gupta 0001', 'Luca Trevisan', 'Moses Charikar', 'Omer Reingold', 'Sanjeev Khanna']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Autore con maggior numero di collaboratori\n",
    "\n",
    "def get_author_with_most_collaborotors(G:nx.Graph)->tuple:\n",
    "    authors = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 1}\n",
    "    authors = list(authors)\n",
    "\n",
    "    max = {\"author\": \"None\",\"collaborators\":list()}\n",
    "    for author in authors:\n",
    "        collaborators = set()\n",
    "        publication_ids = [publication_id[1] for publication_id in list(G.edges(author))]\n",
    "        for publication_id in publication_ids:\n",
    "            collaborators.update(\n",
    "                [publication_id[1] for publication_id in list(G.edges(publication_id))]\n",
    "            )\n",
    "        collaborators = list(collaborators)\n",
    "        collaborators.remove(author)\n",
    "        if len(collaborators)  > len(max[\"collaborators\"]):\n",
    "            max[\"author\"] = author\n",
    "            max[\"collaborators\"] = collaborators\n",
    "    return(\n",
    "        max['author'],\n",
    "        len(max['collaborators']),\n",
    "        max['collaborators']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    author, count, collaborators = get_author_with_most_collaborotors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"The author with most collaborators is {author}, with {count} collaborators:\\n{collaborators}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_connected_component(G:nx.Graph)->nx.Graph:\n",
    "    return G.subgraph(\n",
    "    sorted(nx.connected_components(G), key = len, reverse=True)[0]\n",
    "    ).copy()\n",
    "    \n",
    "def find_farther_node(G,starting_node:str)->list:\n",
    "    edges = nx.bfs_edges(G,starting_node)\n",
    "    edges = [starting_node] + [v for u, v in edges]\n",
    "    return list(G.edges(edges[-1]))[0][0]\n",
    "\n",
    "def two_sweep_path(G:nx.Graph,starting_node:str)->list:\n",
    "    a = find_farther_node(G,starting_node)\n",
    "    b = find_farther_node(G,a)\n",
    "    return nx.shortest_path(G,a,b)\n",
    "\n",
    "def calculate_starting_node(G: nx.Graph, method: str = \"random\") -> str:\n",
    "    lcc = get_largest_connected_component(G)\n",
    "\n",
    "    if method == \"random\":\n",
    "        starting_node = list(lcc)[0]\n",
    "    elif method == \"2-sweep\":\n",
    "        starting_node = two_sweep_path(lcc, list(lcc)[0])\n",
    "        median_idx = len(starting_node) // 2\n",
    "        starting_node = starting_node[median_idx]\n",
    "    else:\n",
    "        raise ValueError(\"Metodo non valido. Usare 'random' o '2-sweep'.\")\n",
    "\n",
    "    return starting_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph out-dblp_article has diameter: 4\n",
      "Graph out-dblp_book has diameter: 1\n",
      "Graph out-dblp_incollection has diameter: 4\n",
      "Graph out-dblp_inproceedings has diameter: 5\n",
      "Graph out-dblp_mastersthesis has diameter: 1\n",
      "Graph out-dblp_phdthesis has diameter: 1\n",
      "Graph out-dblp_proceedings has diameter: 2\n"
     ]
    }
   ],
   "source": [
    "# Calcolo del Diametro\n",
    "\n",
    "def calculate_B_i(G:nx.Graph, nodes:dict, i:int):\n",
    "    F = list()\n",
    "    for key in nodes.keys():\n",
    "        if nodes[key] == i:\n",
    "            F.append(key)\n",
    "    B_i = 0\n",
    "    for node in F:\n",
    "        max = nx.eccentricity(G, v=node)\n",
    "        if max > B_i:\n",
    "            B_i = max\n",
    "    return B_i\n",
    "\n",
    "def calculate_B_i_array(G,nx.Graph,i:int):\n",
    "    nodes_ecc = nx.eccentricity(G)\n",
    "    B_i_array = np.empty(shape=i, dtype=int)\n",
    "    for idx in range(i):\n",
    "        B_i_array[idx] = calculate_B_i(G,nodes,i)\n",
    "    return B_i_array\n",
    "\n",
    "\n",
    "def iFub(G:nx.Graph,node:str)-> int:\n",
    "    lcc = get_largest_connected_component(G)\n",
    "    i = nx.eccentricity(lcc,v=node)\n",
    "\n",
    "    lb = i\n",
    "    ub = 2*lb\n",
    "    \n",
    "    B_i = calculate_B_i_array(lcc,node,i)\n",
    "    \n",
    "    while ub > lb:\n",
    "        B_i = calculate_B_i(lcc,node,i)\n",
    "        max = np.max([lb,B_i])\n",
    "        if max > 2*(i-1):\n",
    "            return max\n",
    "        else:\n",
    "            lb = max\n",
    "            ub = 2*(i-1)\n",
    "        i=i-1\n",
    "    return lb\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    diameter = iFub(G, calculate_starting_node(G,method=\"2-sweep\"))\n",
    "    #nx_diameter = nx.diameter(get_largest_connected_component(G))\n",
    "    print(f\"Graph {df_list[idx].name} has diameter: {diameter}\")\n",
    "    #print(f\"NetworkX diameter is {nx_diameter}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_DataFrame_from_list(df_list:list[pd.DataFrame])->pd.DataFrame:\n",
    "    df = pd.concat(\n",
    "        df_list,\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df.drop_duplicates(\n",
    "        subset='title',\n",
    "        keep='first',\n",
    "        inplace=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_union_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    return create_graph(\n",
    "        concatenate_DataFrame_from_list(df_list)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_union_graph_from_DataFrame_list(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_to_all_main_questions(G:nx.Graph,name:str)->None:\n",
    "    print(f\"-------------Graph: {name}--------------\\n\")\n",
    "\n",
    "    title, authors, counter = get_publication_with_max_authors(G)\n",
    "    print(\"The publication with most authors is:\")\n",
    "    print(f\"{title} \\n wich has {counter} authors\\n\")\n",
    "\n",
    "    diameter = iFub(G, calculate_starting_node(G))\n",
    "    #nx_diameter = nx.diameter(get_largest_connected_component(G))\n",
    "    print(f\"The graph has exact diameter: {diameter}\")\n",
    "    #print(f\"Diameter calculated with NetworkX is: {nx_diameter}\\n\")\n",
    "\n",
    "    author, count, collaborators = get_author_with_most_collaborotors(G)\n",
    "    print(f\"The author with most collaborators is {author}, with {count} collaborators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_to_all_main_questions(\n",
    "    G,\n",
    "    \"Union\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def build_authors_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    df = concatenate_DataFrame_from_list(df_list)\n",
    "    df = df[\"author\"]\n",
    "    G = nx.Graph()\n",
    "    for authors in df:\n",
    "        authors_list = authors.split(\"|\")\n",
    "\n",
    "\n",
    "        \n",
    "        for author_comb in itertools.combinations(authors_list,2):\n",
    "            if G.has_edge(*author_comb):\n",
    "                G[author_comb[0]][author_comb[1]][\"weight\"] += 1\n",
    "            else:\n",
    "                G.add_edge(*author_comb,weight = 1)\n",
    "    return G\n",
    "\n",
    "def find_most_collaborating_couple(G:nx.Graph)->tuple[str,str,dict[int]]:\n",
    "    return  sorted(G.edges(data=True),key= lambda x: x[2]['weight'],reverse=True)[0]\n",
    "\n",
    "author_1, author_2, weight = find_most_collaborating_couple(\n",
    "    build_authors_graph_from_DataFrame_list(df_list)\n",
    "    )\n",
    "\n",
    "print(f\"The most collaborating authors are {author_1} and {author_2} with {weight['weight']} collaborations togheter \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apad",
   "language": "python",
   "name": "apad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

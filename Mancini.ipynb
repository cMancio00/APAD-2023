{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di fine corso Algoritmi e programmazione per l'analisi dei dati 2022-2023\n",
    "\n",
    "Il progetto prevede di rispondere a delle domande che verranno enunciate in seguito, analizzando un insieme di datests contenenti le informazioni sulle pubblicazioni scientifiche.\n",
    "Lo scopo è quello di effettuare l'analisi utilizzando algoritmi sui grafi.\n",
    "La libreria utilizzata per la costruzioni e metodi di utilità di grafi è [NetworkX](https://networkx.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operazioni preliminari\n",
    "\n",
    "Prima di iniziare l'alalisi, importiamo i principali moduli che usere:\n",
    "\n",
    "- [NetworkX](https://networkx.org/)\n",
    "- [Pandas](https://pandas.pydata.org/)\n",
    "- [Numpy](https://numpy.org/)\n",
    "\n",
    "Queste sono le librerie più usate in ambito di analisi dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essendo i dataset dei file csv, li cerchiamo all'interno della cartella del progetto, più precisamente ci aspettiamo che sia in una cartella chiamata `Data`.\n",
    "\n",
    "Utilizzando il metodo `os.listdir(nome_path)` del modulo integrato di Python `os`, possiamo ottenere una lista con i nomi di tutti i file in quella cartella.\n",
    "\n",
    "> Simile al comando shell `ls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"Data\"\n",
    "csv_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto possiamo leggere i csv.\n",
    "La lettura è eseguita utilizzando la libreria `pandas`.\n",
    "Essa offre una conveniente struttura dati per la rappresentazione di un dataset che prende il nome di `DataFrame`. Può essere visto come una matrice, implementata tramite lista di liste.\n",
    "\n",
    "Una lettura molto semplice richiede solo la specifica del nome del csv da leggere e il metodo `read_csv` restituirà un `DataFrame`.\n",
    "\n",
    "Nel codice sottostante è stato eseguito un wrapper del metodo sopra citato.\n",
    "Sappiamo in anticipo che colonne leggere, fatta eccezione di un unico file `out-dblp_proceedings.csv`, che ha una colonna diversa, ma con lo stesso significato al fine della nostra analisi.\n",
    "\n",
    "L'operazione aggiuntiva è stata quella di dare un nome al Dataframe (che sarà comodo più avanti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name:str)->pd.DataFrame:\n",
    "    cols = [\"id\",\"author\",\"title\"]\n",
    "    if name == \"out-dblp_proceedings.csv\":\n",
    "        cols = [\"id\",\"editor\",\"title\"]\n",
    "        \n",
    "    df = pd.read_csv(\n",
    "    path +\"/\" + name,\n",
    "    delimiter=\";\",\n",
    "    usecols=cols,\n",
    "    #nrows=5000\n",
    "    )\n",
    "    df.name = name.split(\".\")[0]\n",
    "    df.rename(columns={\"editor\":\"author\"}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione della lista dei DataFrame\n",
    "\n",
    "Una volta che abbiamo una funzione per leggere i csv nel modo che desideriamo, ciò che vogliamo ottenere è una lista di dataframe da poter utilizzare in seguito.\n",
    "\n",
    "Questo problema è facilmente risolvibile con un ciclo. In aggiunta, essendoci dei valori nulli, li togliamo a lettutra ultimata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "for csv in csv_list:\n",
    "    df_list.append(\n",
    "        read_csv(csv)\n",
    "    )\n",
    "    df_list[-1].dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio di DataFrame\n",
    "\n",
    "Di seguito vengono riportate le prime 5 righe del primo DataFrame creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: out-dblp_article\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4105295</td>\n",
       "      <td>Clement T. Yu|Hai He|Weiyi Meng|Yiyao Lu|Zongh...</td>\n",
       "      <td>Towards Deeper Understanding of the Search Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4106479</td>\n",
       "      <td>Fatih Gelgi|Hasan Davulcu|Srinivas Vadrevu</td>\n",
       "      <td>Information Extraction from Web Pages Using Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4107897</td>\n",
       "      <td>Daniel A. Menascé|Vasudeva Akula</td>\n",
       "      <td>Improving the Performance of Online Auctions T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4108498</td>\n",
       "      <td>Hongjian Fan|Kotagiri Ramamohanarao</td>\n",
       "      <td>Patterns Based Classifiers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4108959</td>\n",
       "      <td>Bing Liu 0001|Yanhong Zhai</td>\n",
       "      <td>Extracting Web Data Using Instance-Based Learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             author  \\\n",
       "3  4105295  Clement T. Yu|Hai He|Weiyi Meng|Yiyao Lu|Zongh...   \n",
       "4  4106479         Fatih Gelgi|Hasan Davulcu|Srinivas Vadrevu   \n",
       "5  4107897                   Daniel A. Menascé|Vasudeva Akula   \n",
       "6  4108498                Hongjian Fan|Kotagiri Ramamohanarao   \n",
       "7  4108959                         Bing Liu 0001|Yanhong Zhai   \n",
       "\n",
       "                                               title  \n",
       "3  Towards Deeper Understanding of the Search Int...  \n",
       "4  Information Extraction from Web Pages Using Pr...  \n",
       "5  Improving the Performance of Online Auctions T...  \n",
       "6                        Patterns Based Classifiers.  \n",
       "7  Extracting Web Data Using Instance-Based Learn...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Name: {df_list[0].name}\")\n",
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione dei Grafi\n",
    "\n",
    "Passiamo ora alla creazione del `Grafo`. Vogliamo costruire un grafo bipartito, contenente in un insieme gli `autori` e nell' altro i `titoli`.\n",
    "\n",
    "Ciò che dobbiamo fare è dividere i vari autori di una singola pubblicazione e creare i nodi e archi desiderati.\n",
    "\n",
    "> Gli autori sono separati da carattere `|`.\n",
    "\n",
    "Per comodità come attributo di ogni nodo degli autori, inseriamo il conteggio degli autori che hanno partecipato a tale pubblicazione. (Questo passaggio può essere evitato perchè corrisponde al grado di tale nodo).\n",
    "\n",
    "Appendiamo in una lista i vari grafi che abbiamo creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df:pd.DataFrame)->nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    for publication_id, row in df.iterrows():\n",
    "        authors = row[\"author\"].split(\"|\")\n",
    "        title = row[\"title\"]\n",
    "        G.add_node(publication_id, bipartite = 0, title=title, authors_counter = len(authors))\n",
    "        for author in authors:\n",
    "            G.add_node(author, bipartite = 1)\n",
    "            G.add_edge(publication_id,author)\n",
    "    return G\n",
    "\n",
    "graph_list = list()\n",
    "for df in df_list:\n",
    "    graph_list.append(\n",
    "        create_graph(df)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note su una possibile implementazione parallela.\n",
    "La creazione del grafo di NetworkX avviene in maniera sequenziale ed è chiaramente un'operazione non vettorizzabile. Tuttavia sapendo in anticipo (come nel nostro caso) il numero di grafi da costruire, fornendo una struttura dati di output con la stessa dimensione del numero di grafi da costruire possiamo eseguire in parallelo sulla CPU la creazione di tali grafi. Naturalmente vanno fatte considerazioni aggiuntive sull'utilizzo della memoria.\n",
    "\n",
    "La libreria più semplice da usare per gestire il parallelismo sulla CPU (senza dover instanziare altri interpreti) è probabilmente [Numba](https://numba.pydata.org/), che ci permette di avere un compilatore *just in time*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubblicazione con maggior numero di autori\n",
    "\n",
    "Per trovare la pubblicazione con il maggior numero di autori, dobbiamo visitare il grafo nel seguente modo:\n",
    "1. Selezionare tutti i nodi delle  pubblicazioni\n",
    "2. All'interno di questi nodi è presente il campo `author_counter`.\n",
    "3. Castando la lista ad array di `numpy`, possiamo utilizzare `argmax`.\n",
    "4. Avendo l'id della pubblicazione selezioniamo il campo `titolo`.\n",
    "\n",
    "> Se non avessimo avuto il campo `author_counter`, avremmo potuto contare il grado del nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "Making Bertha Drive - An Autonomous Journey on a Historic Route.\n",
      "With 31 authors.\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "The Munich Project CIP, Volume I: The Wide Spectrum Language CIP-L\n",
      "With 18 authors.\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "CoolEmAll: Models and Tools for Planning and Operating Energy Efficient Data Centres.\n",
      "With 19 authors.\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "R-GMA: An Information Integration System for Grid Monitoring.\n",
      "With 21 authors.\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "Shadow Paging Is Feasible.\n",
      "With 1 authors.\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "Datenbankgestütztes Kosten- und Erlöscontrolling: Konzept und Realisierung einer entscheidungsorienerten Erfolgsrechnung.\n",
      "With 2 authors.\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "Workshop Proceedings of the 8th International Conference on Intelligent Environments, Guanajuato, Mexico, June 26-29, 2012\n",
      "With 22 authors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_publication_with_max_authors(G:nx.Graph)->tuple[str,int]:\n",
    "    publication_ids = list(n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0)\n",
    "\n",
    "    authors_counter_array = np.array(\n",
    "        list(map(lambda id: G.nodes[id][\"authors_counter\"], publication_ids))\n",
    "        )\n",
    "\n",
    "    max_authors_pubication_id = publication_ids[authors_counter_array.argmax()]\n",
    "\n",
    "    title = G.nodes[max_authors_pubication_id][\"title\"]\n",
    "\n",
    "    return (\n",
    "        title,\n",
    "        G.nodes[max_authors_pubication_id]['authors_counter']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    title, counter = get_publication_with_max_authors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"{title}\\nWith {counter} authors.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autore con maggior numero di collaborazioni\n",
    "\n",
    "Per trovare l'autore con il maggior numero di collaboratori dobbiamo:\n",
    "\n",
    "1. Selezionare tutti i nodi degli autori.\n",
    "2. Per ognuno degli autori selezioniore le proprie pubblicazioni.\n",
    "3. Per ogni pubblicazione salvarsi i collaboratori (ad esempio in una lista).\n",
    "4. La lista più grande (una per ogni autore) corrisponde alla risposta della domanda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "Edmond Bianco, with 169 collaborators.\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "Bertrand Meyer 0001, with 15 collaborators.\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "Christian S. Jensen, with 79 collaborators.\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "Ali Özen, with 28 collaborators.\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "Tatu Ylönen, with 1 collaborators.\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "Alberto Bonanno, with 2 collaborators.\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "Joaquim Filipe, with 83 collaborators.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_author_with_most_collaborations(G:nx.Graph)->tuple[str,int]:\n",
    "    authors = list(n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 1)\n",
    "\n",
    "    max = {\"author\": \"None\",\"collaborators\":list(),\"count\":0}\n",
    "    for author in authors:\n",
    "        collaborators = list()\n",
    "        publication_ids = [publication_id[1] for publication_id in list(G.edges(author))]\n",
    "        for publication_id in publication_ids:\n",
    "            collaborators.append(\n",
    "                [publication_id[1] for publication_id in list(G.edges(publication_id))]\n",
    "            )\n",
    "        if len(collaborators)  > max[\"count\"]:\n",
    "            max[\"author\"] = author\n",
    "            max[\"count\"] = len(collaborators)\n",
    "    return(\n",
    "        max['author'],\n",
    "        max[\"count\"]\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    author, count= get_author_with_most_collaborations(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"{author}, with {count} collaborators.\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo del Diametro\n",
    "\n",
    "Per il calcolo del Diametro utiliziamo l'algoritmo `iFub` visto a lezione.\n",
    "\n",
    "Dobbiamo prima implementare delle funzioni di utilità quali:\n",
    "- Calcolo della componente fortemente connessa più grande (il grafo risultante non è connesso e quindi l'algoritmo non funzionerebbe).\n",
    "- Scelta del nodo iniziale\n",
    "- `two-sweep`\n",
    "\n",
    "Per il calcolo del nodo iniziale abbiamo due opzioni, selezionabili durante la chiamata del metodo:\n",
    "1. Nodo casuale\n",
    "2. Nodo *mediano* nel cammino del **two-sweep**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_connected_component(G:nx.Graph)->nx.Graph:\n",
    "    return G.subgraph(\n",
    "    sorted(nx.connected_components(G), key = len, reverse=True)[0]\n",
    "    ).copy()\n",
    "    \n",
    "def find_farther_node(G,starting_node:str)->list:\n",
    "    edges = nx.bfs_edges(G,starting_node)\n",
    "    edges = [starting_node] + [v for u, v in edges]\n",
    "    return list(G.edges(edges[-1]))[0][0]\n",
    "\n",
    "def two_sweep_path(G:nx.Graph,starting_node:str)->list:\n",
    "    a = find_farther_node(G,starting_node)\n",
    "    b = find_farther_node(G,a)\n",
    "    return nx.shortest_path(G,a,b)\n",
    "\n",
    "from random import choice\n",
    "def calculate_starting_node(G: nx.Graph, method: str = \"random\") -> str:\n",
    "    random_node = choice(list(G.nodes))\n",
    "    if method == \"random\":\n",
    "        return random_node\n",
    "    elif method == \"2-sweep\":\n",
    "        starting_node = two_sweep_path(G, random_node)\n",
    "        median_idx = len(starting_node) // 2\n",
    "        starting_node = starting_node[median_idx]\n",
    "    else:\n",
    "        raise ValueError(\"Metodo non valido. Usare 'random' o '2-sweep'.\")\n",
    "\n",
    "    return starting_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per il calcolo del diametro con `iFub` dobbiamo anche implementare le funzioni per il calcolo dell'insieme $F_i(u)$ e $B_i(u)$, con $u$ nodo iniziale.\n",
    "\n",
    "Il diametro calcolato nel seguente modo restituisce (nei test effettuati) lo stesso numero del metodo [`diameter()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.distance_measures.diameter.html) di NetwokX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_F(G:nx.Graph,node:str,distance:int)->set:\n",
    "    return nx.descendants_at_distance(G,node,distance)\n",
    "\n",
    "def calculate_B_i(G:nx.Graph, node:str, i:int)->int:\n",
    "    F = calculate_F(G,node,distance=i)\n",
    "    B_i = 0\n",
    "    for node in F:\n",
    "        max = nx.eccentricity(G, v=node)\n",
    "        if max > B_i:\n",
    "            B_i = max\n",
    "    return B_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph out-dblp_article has diameter: 52\n",
      "NetworkX diameter is: 52\n",
      "\n",
      "Graph out-dblp_book has diameter: 6\n",
      "NetworkX diameter is: 6\n",
      "\n",
      "Graph out-dblp_incollection has diameter: 9\n",
      "NetworkX diameter is: 9\n",
      "\n",
      "Graph out-dblp_inproceedings has diameter: 66\n",
      "NetworkX diameter is: 66\n",
      "\n",
      "Graph out-dblp_mastersthesis has diameter: 1\n",
      "NetworkX diameter is: 1\n",
      "\n",
      "Graph out-dblp_phdthesis has diameter: 2\n",
      "NetworkX diameter is: 2\n",
      "\n",
      "Graph out-dblp_proceedings has diameter: 68\n",
      "NetworkX diameter is: 68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def iFub(G:nx.Graph, start_method:str = \"random\")-> int:\n",
    "    G = get_largest_connected_component(G)\n",
    "    node = calculate_starting_node(G,method=start_method)\n",
    "    i = nx.eccentricity(G,v=node)\n",
    "\n",
    "    lb = i\n",
    "    ub = 2*lb\n",
    "    \n",
    "    while ub > lb:\n",
    "        B_i = calculate_B_i(G,node,i)\n",
    "        max = np.max([lb,B_i])\n",
    "        if max > 2*(i-1):\n",
    "            return max\n",
    "        else:\n",
    "            lb = max\n",
    "            ub = 2*(i-1)\n",
    "        i=i-1\n",
    "    return lb\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    diameter = iFub(G)\n",
    "    print(f\"Graph {df_list[idx].name} has diameter: {diameter}\")\n",
    "    #print(f\"NetworkX diameter is: {nx.diameter(get_largest_connected_component(G))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafo Unione\n",
    "\n",
    "Avendo la lista di DataFrame, la creazione del grafo unione si riduce ai seguenti passaggi:\n",
    "1. Concatenazione dei DataFrame (eliminando i duplicati)\n",
    "2. Creazione del Grafo come desctritto nel paragrafi precedenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_DataFrame_from_list(df_list:list[pd.DataFrame])->pd.DataFrame:\n",
    "    df = pd.concat(\n",
    "        df_list,\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df.drop_duplicates(\n",
    "        subset='title',\n",
    "        keep='first',\n",
    "        inplace=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_union_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    return create_graph(\n",
    "        concatenate_DataFrame_from_list(df_list)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_union_graph_from_DataFrame_list(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto avendo il grafo nella stessa forma dei precedenti, possiamo applicare le solite \n",
    "funzioni per trovare le risposte alle domande.\n",
    "\n",
    "In questo caso è stata creata una funzione che comprende la chiamata a tutte le funzioni per rispondere alle domande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_to_all_main_questions(G:nx.Graph,name:str)->None:\n",
    "    print(f\"-------------Graph: {name}--------------\\n\")\n",
    "\n",
    "    title,counter = get_publication_with_max_authors(G)\n",
    "    print(\"The publication with most authors is:\")\n",
    "    print(f\"{title} \\nWich has {counter} authors\\n\")\n",
    "\n",
    "    author, count= get_author_with_most_collaborations(G)\n",
    "    print(f\"{author}, with {count} collaborators.\\n\")\n",
    "    \n",
    "    diameter = iFub(G)\n",
    "    print(f\"The graph diameter is: {diameter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: Union--------------\n",
      "\n",
      "The publication with most authors is:\n",
      "Making Bertha Drive - An Autonomous Journey on a Historic Route. \n",
      "Wich has 31 authors\n",
      "\n",
      "Edmond Bianco, with 162 collaborators.\n",
      "\n",
      "The graph diameter is: 92\n"
     ]
    }
   ],
   "source": [
    "answer_to_all_main_questions(\n",
    "    G,\n",
    "    \"Union\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autori con più collaborazioni insieme.\n",
    "\n",
    "Per rispondere a questa domanda dobbiamo prima creare il grafo degli autori, che sarà un grafo pesato.\n",
    "\n",
    "Durante la creazione del grafo, un arco corrisponde ad una collaboraione, ogni volta che due autori collaborano, il peso del loro arco viene incrementato di uno.\n",
    "\n",
    "Avendolo strutturato in questo modo, il problema si riduce a trovare l'arco con il peso maggiore.\n",
    "Possiamo convenientemente usare una funzione che si comporta nel seguente modo:\n",
    "1. Prende tutti gli archi (con i relativi dati) dal grafo.\n",
    "2. Ordina *al contrario* usando come chiave il campo `weight`.\n",
    "3. Prende il primo elemento della lista ottenuta.\n",
    "\n",
    "> L'espressione `lambda x: x[2]['weight']` potrebbe confondere. Stiamo decidendo quale siano le chiavi per ordinare e stiamo dicendo che: Ad ogni elemento della lista bisogna prendere il secondo campo (partendo da 0) che corrisponde al dizionario degli attributi (0 e 1 sono il nome dei nodi comunicanti), in questo dizionario dobbiamo considerare il valore della chiave `weight`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most collaborating authors are Richard T. Snodgrass and Christian S. Jensen with 33 collaborations togheter \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def build_authors_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    df = concatenate_DataFrame_from_list(df_list)\n",
    "    df = df[\"author\"]\n",
    "    G = nx.Graph()\n",
    "    for authors in df:\n",
    "        authors_list = authors.split(\"|\")\n",
    "        for author_comb in itertools.combinations(authors_list,2):\n",
    "            if G.has_edge(*author_comb):\n",
    "                G[author_comb[0]][author_comb[1]][\"weight\"] += 1\n",
    "            else:\n",
    "                G.add_edge(*author_comb,weight = 1)\n",
    "    return G\n",
    "\n",
    "def find_most_collaborating_couple(G:nx.Graph)->tuple[str,str,dict[int]]:\n",
    "    return  sorted(G.edges(data=True),key= lambda x: x[2]['weight'],reverse=True)[0]\n",
    "\n",
    "author_1, author_2, weight = find_most_collaborating_couple(\n",
    "    build_authors_graph_from_DataFrame_list(df_list)\n",
    "    )\n",
    "\n",
    "print(f\"The most collaborating authors are {author_1} and {author_2} with {weight['weight']} collaborations togheter \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apad",
   "language": "python",
   "name": "apad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di fine corso Algoritmi e programmazione per l'analisi dei dati 2022-2023\n",
    "\n",
    "Il progetto prevede di rispondere a delle domande che verranno enunciate in seguito, analizzando un insieme di datests contenenti le informazioni sulle pubblicazioni scientifiche.\n",
    "Lo scopo è quello di effettuare l'analisi utilizzando algoritmi sui grafi.\n",
    "La libreria utilizzata per la costruzioni e metodi di utilità di grafi è [NetworkX](https://networkx.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operazioni preliminari\n",
    "\n",
    "Prima di iniziare l'alalisi, importiamo i principali moduli che usere:\n",
    "\n",
    "- [NetworkX](https://networkx.org/)\n",
    "- [Pandas](https://pandas.pydata.org/)\n",
    "- [Numpy](https://numpy.org/)\n",
    "\n",
    "Queste sono le librerie più usate in ambito di analisi dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essendo i dataset dei file csv, li cerchiamo all'interno della cartella del progetto, più precisamente ci aspettiamo che sia in una cartella chiamata `Data`.\n",
    "\n",
    "Utilizzando il metodo `os.listdir(nome_path)` del modulo integrato di Python `os`, possiamo ottenere una lista con i nomi di tutti i file in quella cartella.\n",
    "> Simile al comando shell `ls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"Data\"\n",
    "csv_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto possiamo leggere i csv.\n",
    "La lettura è eseguita utilizzando la libreria `pandas`.\n",
    "Essa offre una conveniente struttura dati per la rappresentazione di un dataset che prende il nome di `DataFrame`. Può essere visto come una matrice, implementata tramite lista di liste.\n",
    "\n",
    "Una lettura molto semplice richiede solo la specifica del nome del csv da leggere e il metodo `read_csv` restituirà un `DataFrame`.\n",
    "\n",
    "Nel codice sottostante è stato eseguito un wrapper del metodo sopra citato.\n",
    "Sappiamo in anticipo che colonne leggere, fatta eccezione di un unico file `out-dblp_proceedings.csv`, che ha una colonna diversa, ma con lo stesso significato al fine della nostra analisi.\n",
    "\n",
    "L'operazione aggiuntiva è stata quella di dare un nome al Dataframe (che sarà comodo più avanti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name:str)->pd.DataFrame:\n",
    "    cols = [\"id\",\"author\",\"title\"]\n",
    "    if name == \"out-dblp_proceedings.csv\":\n",
    "        cols = [\"id\",\"editor\",\"title\"]\n",
    "        \n",
    "    df = pd.read_csv(\n",
    "    path +\"/\" + name,\n",
    "    delimiter=\";\",\n",
    "    usecols=cols,\n",
    "    nrows=1000\n",
    "    )\n",
    "    df.name = name.split(\".\")[0]\n",
    "    df.rename(columns={\"editor\":\"author\"}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione della lista dei DataFrame\n",
    "\n",
    "Una volta che abbiamo una funzione per leggere i csv nel modo che desideriamo, ciò che vogliamo ottenere è una lista di dataframe da poter utilizzare in seguito.\n",
    "\n",
    "Questo problema è facilmente risolvibile con un ciclo. In aggiunta, essendoci dei valori nulli, li togliamo a lettutra ultimata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "for csv in csv_list:\n",
    "    df_list.append(\n",
    "        read_csv(csv)\n",
    "    )\n",
    "    df_list[-1].dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio di DataFrame\n",
    "\n",
    "Di seguito vengono riportate le prime 5 righe del primo DataFrame creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: out-dblp_article\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4105295</td>\n",
       "      <td>Clement T. Yu|Hai He|Weiyi Meng|Yiyao Lu|Zongh...</td>\n",
       "      <td>Towards Deeper Understanding of the Search Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4106479</td>\n",
       "      <td>Fatih Gelgi|Hasan Davulcu|Srinivas Vadrevu</td>\n",
       "      <td>Information Extraction from Web Pages Using Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4107897</td>\n",
       "      <td>Daniel A. Menascé|Vasudeva Akula</td>\n",
       "      <td>Improving the Performance of Online Auctions T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4108498</td>\n",
       "      <td>Hongjian Fan|Kotagiri Ramamohanarao</td>\n",
       "      <td>Patterns Based Classifiers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4108959</td>\n",
       "      <td>Bing Liu 0001|Yanhong Zhai</td>\n",
       "      <td>Extracting Web Data Using Instance-Based Learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             author  \\\n",
       "3  4105295  Clement T. Yu|Hai He|Weiyi Meng|Yiyao Lu|Zongh...   \n",
       "4  4106479         Fatih Gelgi|Hasan Davulcu|Srinivas Vadrevu   \n",
       "5  4107897                   Daniel A. Menascé|Vasudeva Akula   \n",
       "6  4108498                Hongjian Fan|Kotagiri Ramamohanarao   \n",
       "7  4108959                         Bing Liu 0001|Yanhong Zhai   \n",
       "\n",
       "                                               title  \n",
       "3  Towards Deeper Understanding of the Search Int...  \n",
       "4  Information Extraction from Web Pages Using Pr...  \n",
       "5  Improving the Performance of Online Auctions T...  \n",
       "6                        Patterns Based Classifiers.  \n",
       "7  Extracting Web Data Using Instance-Based Learn...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Name: {df_list[0].name}\")\n",
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione dei Grafi\n",
    "\n",
    "Passiamo ora alla creazione del `Grafo`. Vogliamo costruire un grafo bipartito, contenente in un insieme gli `autori` e nell' altro i `titoli`.\n",
    "\n",
    "Ciò che dobbiamo fare è dividere i vari autori di una singola pubblicazione e creare i nodi e archi desiderati.\n",
    "> Gli autori sono separati da carattere `|`.\n",
    "\n",
    "Per comodità come attributo di ogni nodo degli autori, inseriamo il conteggio degli autori che hanno partecipato a tale pubblicazione. (Questo passaggio può essere evitato perchè corrisponde al grado di tale nodo).\n",
    "\n",
    "Appendiamo in una lista i vari grafi che abbiamo creato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df:pd.DataFrame)->nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    for publication_id, row in df.iterrows():\n",
    "        authors = row[\"author\"].split(\"|\")\n",
    "        title = row[\"title\"]\n",
    "        G.add_node(publication_id, bipartite = 0, title=title, authors_counter = len(authors))\n",
    "        for author in authors:\n",
    "            G.add_node(author, bipartite = 1)\n",
    "            G.add_edge(publication_id,author)\n",
    "    return G\n",
    "\n",
    "graph_list = list()\n",
    "for df in df_list:\n",
    "    graph_list.append(\n",
    "        create_graph(df)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note su una possibile implementazione parallela.\n",
    "La creazione del grafo di NetworkX avviene in maniera sequenziale ed è chiaramente un'operazione non vettorizzabile. Tuttavia sapendo in anticipo (come nel nostro caso) il numero di grafi da costruire, fornendo una struttura dati di output con la stessa dimensione del numero di grafi da costruire possiamo eseguire in parallelo sulla CPU la creazione di tali grafi. Naturalmente vanno fatte considerazioni aggiuntive sull'utilizzo della memoria.\n",
    "\n",
    "La libreria più semplice da usare per gestire il parallelismo sulla CPU (senza dover instanziare altri interpreti) è probabilmente [Numba](https://numba.pydata.org/), che ci permette di avere un compilatore *just in time*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubblicazione con maggior numero di autori\n",
    "\n",
    "Per trovare la pubblicazione con il maggior numero di autori, dobbiamo visitare il grafo nel seguente modo:\n",
    "1. Selezionare tutti i nodi delle  pubblicazioni\n",
    "2. All'interno di questi nodi è presente il campo `author_counter`.\n",
    "3. Castando la lista ad array di `numpy`, possiamo utilizzare `argmax`.\n",
    "4. Avendo l'id della pubblicazione selezioniamo il campo `titolo`.\n",
    "\n",
    "> Se non avessimo avuto il campo `author_counter`, avremmo potuto contare il grado del nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "ALACRITY: Analytics-Driven Lossless Data Compression for Rapid In-Situ Indexing, Storing, and Querying.\n",
      "With 13 authors.\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "A Framework of Information System Concepts (The FRISCO Report).\n",
      "With 10 authors.\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "CoolEmAll: Models and Tools for Planning and Operating Energy Efficient Data Centres.\n",
      "With 19 authors.\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "R-GMA: An Information Integration System for Grid Monitoring.\n",
      "With 21 authors.\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "Shadow Paging Is Feasible.\n",
      "With 1 authors.\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "Programming Data Structures in Logic.\n",
      "With 1 authors.\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM 2017, Singapore, November 06 - 10, 2017\n",
      "With 15 authors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_publication_with_max_authors(G:nx.Graph)->tuple[str,int]:\n",
    "    publication_ids = list(n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0)\n",
    "\n",
    "    authors_counter_array = np.array(\n",
    "        list(map(lambda id: G.nodes[id][\"authors_counter\"], publication_ids))\n",
    "        )\n",
    "\n",
    "    max_authors_pubication_id = publication_ids[authors_counter_array.argmax()]\n",
    "\n",
    "    title = G.nodes[max_authors_pubication_id][\"title\"]\n",
    "\n",
    "    return (\n",
    "        title,\n",
    "        G.nodes[max_authors_pubication_id]['authors_counter']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    title, counter = get_publication_with_max_authors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"{title}\\nWith {counter} authors.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "The author with most collaborators is Stéphane Bressan, with 24 collaborators:\n",
      "['See-Kiong Ng', 'Shili Xiang', 'Jianneng Cao', 'Antoine Amarilli', 'Baljeet Malhotra', 'Randy Julian', 'Kian-Lee Tan', 'Mouad Hakam', 'Debabrota Basu', 'Wee-Juan Tan', 'Yi Song 0005', 'Ruiming Tang', 'Shaowen Zhou', 'Mingzhe Du', 'Thomas Kister', 'Geong Sen Poh', 'Zihong Yuan', 'Gillian Dobbie', 'Qian Lin', 'Hoang Tam Vo', 'Edward Guyot', 'Pierre Senellart', 'Guilherme Augusto Zagatti', 'Weidong Chen 0004']\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "The author with most collaborators is Sherif Sakr, with 10 collaborators:\n",
      "['Hamid Reza Motahari-Nezhad', 'Daniela Grigori', 'Zuhair Khayyat', 'Seung Hwan Ryu', 'Seyed-Mehdi-Reza Beheshti', 'Faisal Moeen Orakzai', 'Boualem Benatallah', 'Moshe Chai Barukh', 'Ibrahim Abdelaziz', 'Ahmed Gater']\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "The author with most collaborators is Tuncer I. Ören, with 37 collaborators:\n",
      "['Rhys Goldstein', 'Baocun Hou', 'Lance E. Champagne', 'Lin Zhang 0009', 'Mamadou Kaba Traoré', 'Thorsten Pawletta', 'Tingyu Lin', 'Balqies Sadoun', 'Umut Durak', 'Gregory Zacharewicz', 'Azam Khan', 'Mohammad S. Obaidat', 'Nico Formanek', 'Raymond R. Hill', 'Andreas Tolk', 'Ernest H. Page', 'Umang Kant', 'Mayank Singh 0008', 'Jean François Santucci', 'Saikou Y. Diallo', 'Valdemar Vicente Graciano Neto', 'Cláudio Gomes 0001', 'Breno Bernard Nicolau de França', 'Saurabh Mittal', 'Paul A. Fishwick', 'Navonil Mustafee', 'Paul K. Davis', 'Yang Liu', 'Alison Harper', 'Margaret L. Loper', 'Claudia Szabo', 'Juan Manuel Durán', 'Bo Hu Li 0001', 'Yuanjun Laili', 'Laurent Capocchi', 'Maâmar El-Amine Hamri', 'Bernard P. Zeigler']\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "The author with most collaborators is Werner Nutt, with 25 collaborators:\n",
      "['Norbert Podhorszki', 'Laurence Field', 'Abdeslem Djaoui', 'Antony J. Wilson', 'Manfred Oevers', 'Brian A. Coghlan', 'Yaron Kanza', 'Manish Soni', 'Roney Cordenonsi', 'Stuart Kenny', 'Alasdair J. G. Gray', 'Lisha Ma', 'Jason Leake', 'Yakov A. Kogan', 'Sara Cohen', 'Yehoshua Sagiv', 'Steve Fisher', 'Paul Taylor', \"David O'Callaghan\", 'Alexander Serebrenik', 'Steve Hicks', 'Rob Byrom', 'Linda Cornwall', 'Andrew W. Cooke', 'James Magowan']\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "The author with most collaborators is None, with 0 collaborators:\n",
      "[]\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "The author with most collaborators is None, with 0 collaborators:\n",
      "[]\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "The author with most collaborators is Klaus Jansen, with 35 collaborators:\n",
      "['Chandra Chekuri', 'Cristopher Moore', 'Samir Khuller', 'Maria J. Serna', 'Irit Dinur', 'Santosh S. Vempala', 'Anupam Gupta 0001', 'Claire Mathieu', 'Anup Rao 0001', 'Moses Charikar', 'Joseph Naor', 'Dorit S. Hochbaum', 'Uri Zwick', 'Ronitt Rubinfeld', 'José D. P. Rolim', 'Nikhil R. Devanur', 'Eric Blais', 'Ashish Goel', 'Luca Trevisan', 'Chris Umans', 'R. Ravi 0001', 'David Steurer', 'David Williamson', 'Prasad Raghavendra', 'Sofya Raskhodnikova', 'Stefano Leonardi 0001', 'Leslie Ann Goldberg', 'Rocco A. Servedio', 'Josep Díaz', 'Sanjeev Khanna', 'Omer Reingold', 'Vijay V. Vazirani', 'Ronen Shaltiel', 'Dana Ron', 'Naveen Garg 0001']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Autore con maggior numero di collaboratori\n",
    "\n",
    "def get_author_with_most_collaborotors(G:nx.Graph)->tuple:\n",
    "    authors = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 1}\n",
    "    authors = list(authors)\n",
    "\n",
    "    max = {\"author\": \"None\",\"collaborators\":list()}\n",
    "    for author in authors:\n",
    "        collaborators = set()\n",
    "        publication_ids = [publication_id[1] for publication_id in list(G.edges(author))]\n",
    "        for publication_id in publication_ids:\n",
    "            collaborators.update(\n",
    "                [publication_id[1] for publication_id in list(G.edges(publication_id))]\n",
    "            )\n",
    "        collaborators = list(collaborators)\n",
    "        collaborators.remove(author)\n",
    "        if len(collaborators)  > len(max[\"collaborators\"]):\n",
    "            max[\"author\"] = author\n",
    "            max[\"collaborators\"] = collaborators\n",
    "    return(\n",
    "        max['author'],\n",
    "        len(max['collaborators']),\n",
    "        max['collaborators']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    author, count, collaborators = get_author_with_most_collaborotors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"The author with most collaborators is {author}, with {count} collaborators:\\n{collaborators}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_connected_component(G:nx.Graph)->nx.Graph:\n",
    "    return G.subgraph(\n",
    "    sorted(nx.connected_components(G), key = len, reverse=True)[0]\n",
    "    ).copy()\n",
    "    \n",
    "def find_farther_node(G,starting_node:str)->list:\n",
    "    edges = nx.bfs_edges(G,starting_node)\n",
    "    edges = [starting_node] + [v for u, v in edges]\n",
    "    return list(G.edges(edges[-1]))[0][0]\n",
    "\n",
    "def two_sweep_path(G:nx.Graph,starting_node:str)->list:\n",
    "    a = find_farther_node(G,starting_node)\n",
    "    b = find_farther_node(G,a)\n",
    "    return nx.shortest_path(G,a,b)\n",
    "\n",
    "def calculate_starting_node(G: nx.Graph, method: str = \"random\") -> str:\n",
    "    # G = get_largest_connected_component(G)\n",
    "\n",
    "    random_node = choice(list(G.nodes))\n",
    "    if method == \"random\":\n",
    "        return random_node\n",
    "    elif method == \"2-sweep\":\n",
    "        starting_node = two_sweep_path(G, random_node)\n",
    "        median_idx = len(starting_node) // 2\n",
    "        starting_node = starting_node[median_idx]\n",
    "    else:\n",
    "        raise ValueError(\"Metodo non valido. Usare 'random' o '2-sweep'.\")\n",
    "\n",
    "    return starting_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_F(G:nx.Graph,node:str,distance:int)->set:\n",
    "    return nx.descendants_at_distance(G,node,distance)\n",
    "\n",
    "def calculate_B_i(G:nx.Graph, node:str, i:int)->int:\n",
    "    F = calculate_F(G,node,distance=i)\n",
    "    B_i = 0\n",
    "    for node in F:\n",
    "        max = nx.eccentricity(G, v=node)\n",
    "        if max > B_i:\n",
    "            B_i = max\n",
    "    return B_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph out-dblp_article has diameter: 7\n",
      "NetworkX diameter is 7\n",
      "\n",
      "Graph out-dblp_book has diameter: 4\n",
      "NetworkX diameter is 4\n",
      "\n",
      "Graph out-dblp_incollection has diameter: 7\n",
      "NetworkX diameter is 7\n",
      "\n",
      "Graph out-dblp_inproceedings has diameter: 16\n",
      "NetworkX diameter is 16\n",
      "\n",
      "Graph out-dblp_mastersthesis has diameter: 1\n",
      "NetworkX diameter is 1\n",
      "\n",
      "Graph out-dblp_phdthesis has diameter: 1\n",
      "NetworkX diameter is 1\n",
      "\n",
      "Graph out-dblp_proceedings has diameter: 30\n",
      "NetworkX diameter is 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcolo del Diametro\n",
    "def iFub(G:nx.Graph, start_method:str = \"random\")-> int:\n",
    "    G = get_largest_connected_component(G)\n",
    "    node = calculate_starting_node(G,method=start_method)\n",
    "    i = nx.eccentricity(G,v=node)\n",
    "\n",
    "    lb = i\n",
    "    ub = 2*lb\n",
    "    \n",
    "    while ub > lb:\n",
    "        B_i = calculate_B_i(G,node,i)\n",
    "        max = np.max([lb,B_i])\n",
    "        if max > 2*(i-1):\n",
    "            return max\n",
    "        else:\n",
    "            lb = max\n",
    "            ub = 2*(i-1)\n",
    "        i=i-1\n",
    "    return lb\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    diameter = iFub(G)\n",
    "    nx_diameter = nx.diameter(get_largest_connected_component(G))\n",
    "    print(f\"Graph {df_list[idx].name} has diameter: {diameter}\")\n",
    "    print(f\"NetworkX diameter is {nx_diameter}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_DataFrame_from_list(df_list:list[pd.DataFrame])->pd.DataFrame:\n",
    "    df = pd.concat(\n",
    "        df_list,\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df.drop_duplicates(\n",
    "        subset='title',\n",
    "        keep='first',\n",
    "        inplace=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_union_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    return create_graph(\n",
    "        concatenate_DataFrame_from_list(df_list)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_union_graph_from_DataFrame_list(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_to_all_main_questions(G:nx.Graph,name:str)->None:\n",
    "    print(f\"-------------Graph: {name}--------------\\n\")\n",
    "\n",
    "    title, authors, counter = get_publication_with_max_authors(G)\n",
    "    print(\"The publication with most authors is:\")\n",
    "    print(f\"{title} \\n wich has {counter} authors\\n\")\n",
    "\n",
    "    diameter = iFub(G)\n",
    "    #nx_diameter = nx.diameter(get_largest_connected_component(G))\n",
    "    print(f\"The graph has exact diameter: {diameter}\")\n",
    "    #print(f\"Diameter calculated with NetworkX is: {nx_diameter}\\n\")\n",
    "\n",
    "    author, count, collaborators = get_author_with_most_collaborotors(G)\n",
    "    print(f\"The author with most collaborators is {author}, with {count} collaborators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: Union--------------\n",
      "\n",
      "The publication with most authors is:\n",
      "R-GMA: An Information Integration System for Grid Monitoring. \n",
      " wich has 21 authors\n",
      "\n",
      "The graph has exact diameter: 42\n",
      "The author with most collaborators is Tuncer I. Ören, with 37 collaborators\n"
     ]
    }
   ],
   "source": [
    "answer_to_all_main_questions(\n",
    "    G,\n",
    "    \"Union\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most collaborating authors are José D. P. Rolim and Klaus Jansen with 15 collaborations togheter \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def build_authors_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    df = concatenate_DataFrame_from_list(df_list)\n",
    "    df = df[\"author\"]\n",
    "    G = nx.Graph()\n",
    "    for authors in df:\n",
    "        authors_list = authors.split(\"|\")\n",
    "\n",
    "\n",
    "        \n",
    "        for author_comb in itertools.combinations(authors_list,2):\n",
    "            if G.has_edge(*author_comb):\n",
    "                G[author_comb[0]][author_comb[1]][\"weight\"] += 1\n",
    "            else:\n",
    "                G.add_edge(*author_comb,weight = 1)\n",
    "    return G\n",
    "\n",
    "def find_most_collaborating_couple(G:nx.Graph)->tuple[str,str,dict[int]]:\n",
    "    return  sorted(G.edges(data=True),key= lambda x: x[2]['weight'],reverse=True)[0]\n",
    "\n",
    "author_1, author_2, weight = find_most_collaborating_couple(\n",
    "    build_authors_graph_from_DataFrame_list(df_list)\n",
    "    )\n",
    "\n",
    "print(f\"The most collaborating authors are {author_1} and {author_2} with {weight['weight']} collaborations togheter \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apad",
   "language": "python",
   "name": "apad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

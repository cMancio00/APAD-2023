{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"Data\"\n",
    "csv_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name:str)->pd.DataFrame:\n",
    "    cols = [\"id\",\"author\",\"title\"]\n",
    "    if name == \"out-dblp_proceedings.csv\":\n",
    "        cols = [\"id\",\"editor\",\"title\"]\n",
    "        \n",
    "    df = pd.read_csv(\n",
    "    \"Data/\" + name,\n",
    "    delimiter=\";\",\n",
    "    usecols=cols,\n",
    "    nrows=1000\n",
    "    )\n",
    "    df.name = name.split(\".\")[0]\n",
    "    df.rename(columns={\"editor\":\"author\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_list = list()\n",
    "for csv in csv_list:\n",
    "    df_list.append(\n",
    "        read_csv(csv)\n",
    "    )\n",
    "    df_list[-1].dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df:pd.DataFrame)->nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    for publication_id, row in df.iterrows():\n",
    "        authors = row[\"author\"].split(\"|\")\n",
    "        title = row[\"title\"]\n",
    "        G.add_node(publication_id, bipartite = 0, title=title, authors_counter = len(authors))\n",
    "        for author in authors:\n",
    "            G.add_node(author, bipartite = 1)\n",
    "            G.add_edge(publication_id,author)\n",
    "    return G\n",
    "\n",
    "graph_list = list()\n",
    "for df in df_list:\n",
    "    graph_list.append(\n",
    "        create_graph(df)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "ALACRITY: Analytics-Driven Lossless Data Compression for Rapid In-Situ Indexing, Storing, and Querying. \n",
      " ['Choong-Seock Chang', 'David A. Boyuka II', 'Eric R. Schendel', 'Hemanth Kolla', 'Isha Arkatkar', 'Jackie Chen', 'John Jenkins', 'Nagiza F. Samatova', 'Neil Shah', 'Robert B. Ross', 'Scott Klasky', 'Sriram Lakshminarasimhan', 'Stéphane Ethier'] \n",
      " wich has 13 authors\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "A Framework of Information System Concepts (The FRISCO Report). \n",
      " ['Alexander A. Verrijn-Stuart', 'Björn E. Nilsson', 'Colette Rolland', 'Eckhard D. Falkenberg', 'Frans Van Assche', 'J. L. Han Oei', 'Klaus Voss', 'Paul Lindgreen', 'Ronald K. Stamper', 'Wolfgang Hesse'] \n",
      " wich has 10 authors\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "CoolEmAll: Models and Tools for Planning and Operating Energy Efficient Data Centres. \n",
      " ['Andrew Donoghue', 'Ariel Oleksiak', 'Daniel Rathgeb', 'Enric Pages', 'Eugen Volk', 'Georges Da Costa', 'Georgina Gallizo', 'Jaume Salom', 'Jean-Marc Pierson', 'Jochen Buchholz', 'Lara Lopez', 'Laura Sisó', 'Leandro F. Cupertino', 'Mateusz Jarus', 'Micha vor dem Berge', 'Thomas Zilio', 'Tomasz Piontek', 'Uwe Wössner', 'Wojciech Piatek'] \n",
      " wich has 19 authors\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "R-GMA: An Information Integration System for Grid Monitoring. \n",
      " ['Abdeslem Djaoui', 'Alasdair J. G. Gray', 'Andrew W. Cooke', 'Antony J. Wilson', 'Brian A. Coghlan', \"David O'Callaghan\", 'James Magowan', 'Jason Leake', 'Laurence Field', 'Linda Cornwall', 'Lisha Ma', 'Manfred Oevers', 'Manish Soni', 'Norbert Podhorszki', 'Paul Taylor', 'Rob Byrom', 'Roney Cordenonsi', 'Steve Fisher', 'Steve Hicks', 'Stuart Kenny', 'Werner Nutt'] \n",
      " wich has 21 authors\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "Shadow Paging Is Feasible. \n",
      " ['Tatu Ylönen'] \n",
      " wich has 1 authors\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "Programming Data Structures in Logic. \n",
      " ['Russell Turpin'] \n",
      " wich has 1 authors\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM 2017, Singapore, November 06 - 10, 2017 \n",
      " ['Ada Wai-Chee Fu', 'Aixin Sun', 'Carlos Castillo 0001', 'Chenliang Li', 'Debora Donato', 'Ee-Peng Lim', 'Eric Lo 0001', 'J. Shane Culpepper', 'Jimeng Sun 0001', 'Joyce C. Ho', 'Marianne Winslett', 'Mark Sanderson', 'Rakesh Agrawal 0001', 'Vincent S. Tseng', 'Yu Zheng 0004'] \n",
      " wich has 15 authors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pubblicazione con maggior numero di autori:\n",
    "\n",
    "def get_publication_with_max_authors(G:nx.Graph)->tuple[str, list[str], int]:\n",
    "    publication_ids = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    publication_ids = list(publication_ids)\n",
    "\n",
    "    authors_counter_array = np.array(\n",
    "        list(map(lambda id: G.nodes[id][\"authors_counter\"], publication_ids))\n",
    "        )\n",
    "\n",
    "    max_authors_pubication_id = publication_ids[authors_counter_array.argmax()]\n",
    "\n",
    "    authors = G.neighbors(max_authors_pubication_id)\n",
    "    title = G.nodes[max_authors_pubication_id][\"title\"]\n",
    "\n",
    "    return (\n",
    "        title,\n",
    "        list(authors),\n",
    "        G.nodes[max_authors_pubication_id]['authors_counter']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    title, authors, counter = get_publication_with_max_authors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"{title} \\n {list(authors)} \\n wich has {counter} authors\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: out-dblp_article--------------\n",
      "The author with most collaborators is Stéphane Bressan, with 24 collaborators:\n",
      "['See-Kiong Ng', 'Shili Xiang', 'Jianneng Cao', 'Antoine Amarilli', 'Baljeet Malhotra', 'Randy Julian', 'Kian-Lee Tan', 'Mouad Hakam', 'Debabrota Basu', 'Wee-Juan Tan', 'Yi Song 0005', 'Ruiming Tang', 'Shaowen Zhou', 'Mingzhe Du', 'Thomas Kister', 'Geong Sen Poh', 'Zihong Yuan', 'Gillian Dobbie', 'Qian Lin', 'Hoang Tam Vo', 'Edward Guyot', 'Pierre Senellart', 'Guilherme Augusto Zagatti', 'Weidong Chen 0004']\n",
      "\n",
      "-------------Graph: out-dblp_book--------------\n",
      "The author with most collaborators is Sherif Sakr, with 10 collaborators:\n",
      "['Hamid Reza Motahari-Nezhad', 'Daniela Grigori', 'Zuhair Khayyat', 'Seung Hwan Ryu', 'Seyed-Mehdi-Reza Beheshti', 'Faisal Moeen Orakzai', 'Boualem Benatallah', 'Moshe Chai Barukh', 'Ibrahim Abdelaziz', 'Ahmed Gater']\n",
      "\n",
      "-------------Graph: out-dblp_incollection--------------\n",
      "The author with most collaborators is Tuncer I. Ören, with 37 collaborators:\n",
      "['Rhys Goldstein', 'Baocun Hou', 'Lance E. Champagne', 'Lin Zhang 0009', 'Mamadou Kaba Traoré', 'Thorsten Pawletta', 'Tingyu Lin', 'Balqies Sadoun', 'Umut Durak', 'Gregory Zacharewicz', 'Azam Khan', 'Mohammad S. Obaidat', 'Nico Formanek', 'Raymond R. Hill', 'Andreas Tolk', 'Ernest H. Page', 'Umang Kant', 'Mayank Singh 0008', 'Jean François Santucci', 'Saikou Y. Diallo', 'Valdemar Vicente Graciano Neto', 'Cláudio Gomes 0001', 'Breno Bernard Nicolau de França', 'Saurabh Mittal', 'Paul A. Fishwick', 'Navonil Mustafee', 'Paul K. Davis', 'Yang Liu', 'Alison Harper', 'Margaret L. Loper', 'Claudia Szabo', 'Juan Manuel Durán', 'Bo Hu Li 0001', 'Yuanjun Laili', 'Laurent Capocchi', 'Maâmar El-Amine Hamri', 'Bernard P. Zeigler']\n",
      "\n",
      "-------------Graph: out-dblp_inproceedings--------------\n",
      "The author with most collaborators is Werner Nutt, with 25 collaborators:\n",
      "['Norbert Podhorszki', 'Laurence Field', 'Abdeslem Djaoui', 'Antony J. Wilson', 'Manfred Oevers', 'Brian A. Coghlan', 'Yaron Kanza', 'Manish Soni', 'Roney Cordenonsi', 'Stuart Kenny', 'Alasdair J. G. Gray', 'Lisha Ma', 'Jason Leake', 'Yakov A. Kogan', 'Sara Cohen', 'Yehoshua Sagiv', 'Steve Fisher', 'Paul Taylor', \"David O'Callaghan\", 'Alexander Serebrenik', 'Steve Hicks', 'Rob Byrom', 'Linda Cornwall', 'Andrew W. Cooke', 'James Magowan']\n",
      "\n",
      "-------------Graph: out-dblp_mastersthesis--------------\n",
      "The author with most collaborators is None, with 0 collaborators:\n",
      "[]\n",
      "\n",
      "-------------Graph: out-dblp_phdthesis--------------\n",
      "The author with most collaborators is None, with 0 collaborators:\n",
      "[]\n",
      "\n",
      "-------------Graph: out-dblp_proceedings--------------\n",
      "The author with most collaborators is Klaus Jansen, with 35 collaborators:\n",
      "['Chandra Chekuri', 'Cristopher Moore', 'Samir Khuller', 'Maria J. Serna', 'Irit Dinur', 'Santosh S. Vempala', 'Anupam Gupta 0001', 'Claire Mathieu', 'Anup Rao 0001', 'Moses Charikar', 'Joseph Naor', 'Dorit S. Hochbaum', 'Uri Zwick', 'Ronitt Rubinfeld', 'José D. P. Rolim', 'Nikhil R. Devanur', 'Eric Blais', 'Ashish Goel', 'Luca Trevisan', 'Chris Umans', 'R. Ravi 0001', 'David Steurer', 'David Williamson', 'Prasad Raghavendra', 'Sofya Raskhodnikova', 'Stefano Leonardi 0001', 'Leslie Ann Goldberg', 'Rocco A. Servedio', 'Josep Díaz', 'Sanjeev Khanna', 'Omer Reingold', 'Vijay V. Vazirani', 'Ronen Shaltiel', 'Dana Ron', 'Naveen Garg 0001']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Autore con maggior numero di collaboratori\n",
    "\n",
    "def get_author_with_most_collaborotors(G:nx.Graph)->tuple:\n",
    "    authors = {n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 1}\n",
    "    authors = list(authors)\n",
    "\n",
    "    max = {\"author\": \"None\",\"collaborators\":list()}\n",
    "    for author in authors:\n",
    "        collaborators = set()\n",
    "        publication_ids = [publication_id[1] for publication_id in list(G.edges(author))]\n",
    "        for publication_id in publication_ids:\n",
    "            collaborators.update(\n",
    "                [publication_id[1] for publication_id in list(G.edges(publication_id))]\n",
    "            )\n",
    "        collaborators = list(collaborators)\n",
    "        collaborators.remove(author)\n",
    "        if len(collaborators)  > len(max[\"collaborators\"]):\n",
    "            max[\"author\"] = author\n",
    "            max[\"collaborators\"] = collaborators\n",
    "    return(\n",
    "        max['author'],\n",
    "        len(max['collaborators']),\n",
    "        max['collaborators']\n",
    "    )\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    author, count, collaborators = get_author_with_most_collaborotors(G)\n",
    "    print(f\"-------------Graph: {df_list[idx].name}--------------\")\n",
    "    print(f\"The author with most collaborators is {author}, with {count} collaborators:\\n{collaborators}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_connected_component(G:nx.Graph)->nx.Graph:\n",
    "    return G.subgraph(\n",
    "    sorted(nx.connected_components(G), key = len, reverse=True)[0]\n",
    "    ).copy()\n",
    "    \n",
    "def find_farther_node(G,starting_node:str)->list:\n",
    "    edges = nx.bfs_edges(G,starting_node)\n",
    "    edges = [starting_node] + [v for u, v in edges]\n",
    "    return list(G.edges(edges[-1]))[0][0]\n",
    "\n",
    "def two_sweep_path(G:nx.Graph,starting_node:str)->list:\n",
    "    a = find_farther_node(G,starting_node)\n",
    "    b = find_farther_node(G,a)\n",
    "    return nx.shortest_path(G,a,b)\n",
    "\n",
    "def calculate_starting_node(G: nx.Graph, method: str = \"random\") -> str:\n",
    "    # G = get_largest_connected_component(G)\n",
    "\n",
    "    random_node = choice(list(G.nodes))\n",
    "    if method == \"random\":\n",
    "        return random_node\n",
    "    elif method == \"2-sweep\":\n",
    "        starting_node = two_sweep_path(G, random_node)\n",
    "        median_idx = len(starting_node) // 2\n",
    "        starting_node = starting_node[median_idx]\n",
    "    else:\n",
    "        raise ValueError(\"Metodo non valido. Usare 'random' o '2-sweep'.\")\n",
    "\n",
    "    return starting_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_F(G:nx.Graph,node:str,distance:int)->set:\n",
    "    return nx.descendants_at_distance(G,node,distance)\n",
    "\n",
    "def calculate_B_i(G:nx.Graph, node:str, i:int)->int:\n",
    "    F = calculate_F(G,node,distance=i)\n",
    "    B_i = 0\n",
    "    for node in F:\n",
    "        max = nx.eccentricity(G, v=node)\n",
    "        if max > B_i:\n",
    "            B_i = max\n",
    "    return B_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph out-dblp_article has diameter: 7\n",
      "NetworkX diameter is 7\n",
      "\n",
      "Graph out-dblp_book has diameter: 4\n",
      "NetworkX diameter is 4\n",
      "\n",
      "Graph out-dblp_incollection has diameter: 7\n",
      "NetworkX diameter is 7\n",
      "\n",
      "Graph out-dblp_inproceedings has diameter: 16\n",
      "NetworkX diameter is 16\n",
      "\n",
      "Graph out-dblp_mastersthesis has diameter: 1\n",
      "NetworkX diameter is 1\n",
      "\n",
      "Graph out-dblp_phdthesis has diameter: 1\n",
      "NetworkX diameter is 1\n",
      "\n",
      "Graph out-dblp_proceedings has diameter: 30\n",
      "NetworkX diameter is 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcolo del Diametro\n",
    "def iFub(G:nx.Graph, start_method:str = \"random\")-> int:\n",
    "    G = get_largest_connected_component(G)\n",
    "    node = calculate_starting_node(G,method=start_method)\n",
    "    i = nx.eccentricity(G,v=node)\n",
    "\n",
    "    lb = i\n",
    "    ub = 2*lb\n",
    "    \n",
    "    while ub > lb:\n",
    "        B_i = calculate_B_i(G,node,i)\n",
    "        max = np.max([lb,B_i])\n",
    "        if max > 2*(i-1):\n",
    "            return max\n",
    "        else:\n",
    "            lb = max\n",
    "            ub = 2*(i-1)\n",
    "        i=i-1\n",
    "    return lb\n",
    "\n",
    "for idx, G in enumerate(graph_list):\n",
    "    diameter = iFub(G)\n",
    "    nx_diameter = nx.diameter(get_largest_connected_component(G))\n",
    "    print(f\"Graph {df_list[idx].name} has diameter: {diameter}\")\n",
    "    print(f\"NetworkX diameter is {nx_diameter}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_DataFrame_from_list(df_list:list[pd.DataFrame])->pd.DataFrame:\n",
    "    df = pd.concat(\n",
    "        df_list,\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    )\n",
    "    df.drop_duplicates(\n",
    "        subset='title',\n",
    "        keep='first',\n",
    "        inplace=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def build_union_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    return create_graph(\n",
    "        concatenate_DataFrame_from_list(df_list)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_union_graph_from_DataFrame_list(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_to_all_main_questions(G:nx.Graph,name:str)->None:\n",
    "    print(f\"-------------Graph: {name}--------------\\n\")\n",
    "\n",
    "    title, authors, counter = get_publication_with_max_authors(G)\n",
    "    print(\"The publication with most authors is:\")\n",
    "    print(f\"{title} \\n wich has {counter} authors\\n\")\n",
    "\n",
    "    diameter = iFub(G)\n",
    "    #nx_diameter = nx.diameter(get_largest_connected_component(G))\n",
    "    print(f\"The graph has exact diameter: {diameter}\")\n",
    "    #print(f\"Diameter calculated with NetworkX is: {nx_diameter}\\n\")\n",
    "\n",
    "    author, count, collaborators = get_author_with_most_collaborotors(G)\n",
    "    print(f\"The author with most collaborators is {author}, with {count} collaborators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Graph: Union--------------\n",
      "\n",
      "The publication with most authors is:\n",
      "R-GMA: An Information Integration System for Grid Monitoring. \n",
      " wich has 21 authors\n",
      "\n",
      "The graph has exact diameter: 42\n",
      "The author with most collaborators is Tuncer I. Ören, with 37 collaborators\n"
     ]
    }
   ],
   "source": [
    "answer_to_all_main_questions(\n",
    "    G,\n",
    "    \"Union\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most collaborating authors are José D. P. Rolim and Klaus Jansen with 15 collaborations togheter \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def build_authors_graph_from_DataFrame_list(df_list:list[pd.DataFrame])->nx.Graph:\n",
    "    df = concatenate_DataFrame_from_list(df_list)\n",
    "    df = df[\"author\"]\n",
    "    G = nx.Graph()\n",
    "    for authors in df:\n",
    "        authors_list = authors.split(\"|\")\n",
    "\n",
    "\n",
    "        \n",
    "        for author_comb in itertools.combinations(authors_list,2):\n",
    "            if G.has_edge(*author_comb):\n",
    "                G[author_comb[0]][author_comb[1]][\"weight\"] += 1\n",
    "            else:\n",
    "                G.add_edge(*author_comb,weight = 1)\n",
    "    return G\n",
    "\n",
    "def find_most_collaborating_couple(G:nx.Graph)->tuple[str,str,dict[int]]:\n",
    "    return  sorted(G.edges(data=True),key= lambda x: x[2]['weight'],reverse=True)[0]\n",
    "\n",
    "author_1, author_2, weight = find_most_collaborating_couple(\n",
    "    build_authors_graph_from_DataFrame_list(df_list)\n",
    "    )\n",
    "\n",
    "print(f\"The most collaborating authors are {author_1} and {author_2} with {weight['weight']} collaborations togheter \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apad",
   "language": "python",
   "name": "apad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
